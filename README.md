# ARLib
An open-source framework for conducting data poisoning attacks on recommendation systems, designed to assist researchers and practitioners. <br>

**Members:** <br>
Zongwei Wang, Chongqing University, China, zongwei@cqu.edu.cn <br>
Hao Ma, Chongqing University, China, ma_hao@cqu.edu.cn <br>
**Supported by:** <br>
Prof. Min Gao, Chongqing University, China, gaomin@cqu.edu.cn <br>

This repo will be released with our paper in the future.

<h2>Usage</h2>
1. Two configure files **attack_parser.py** and **recommend_parser** are in the directory named conf, and you can select and configure the recommendation model and attack model by modifying the configuration files. <br>
2. Run main.py.

<h2>Requirements</h2>
```
base==1.0.4
numba==0.53.1
numpy==1.18.0
scipy==1.4.1
torch==1.7.1.info
```




